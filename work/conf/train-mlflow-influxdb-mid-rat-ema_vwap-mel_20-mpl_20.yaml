defaults:
 - dataset@create_dataset_kwargs.dataset_kwargs: mid-rat-ema_vwap-mel_20-mpl_20
 - _self_
 
kind: occasional
parent_name: ~
parent_version: ~
parent_stage: ~
model_name: influxdb-mid-rat-ema_vwap-mel_20-mpl_20
create_dataset_kwargs:
  verbose: true
  quant: 3.0e+9
  start: "2022-07-01T00:00:00+00:00"
  stop: "2022-09-01T00:00:00+00:00"
  replace_nan: 1.0
  split: 0.8
  agents:
    influxdb: 
      class: InfluxdbDataset
      batch: 86400.0e+9  # day
      verbose: true
      topics: [ feature ]
      executor:
        class: ProcessPoolExecutor
        max_workers: 1
      feature_keys:
        rat-ema-qv-vwap_20: [ binance-btc-usdt ]
      client:
        timeout: 200000
        verify_ssl: false
dataloader_kwargs:
  train:
    train: true
    num_workers: 16
    batch_size: 1024
  val:
    train: false
    num_workers: 16
    batch_size: 1024
model_kwargs:
  class: TemporalFusionTransformer
  # learning_rate: 0.03125  # 2^-6 1/32 
  # learning_rate: 0.00390625  # 2^-8 1/256 
  # learning_rate: 0.0009765625  # 2^-10 1/1024
  learning_rate: 0.0000152587890625  # 2^-16 1/65536 
  hidden_size: 8
  attention_head_size: 1
  dropout: 0
  hidden_continuous_size: 8
  lstm_layers: 1
  output_size: 1  # Inferred from loss if loss is from pytorch geometric
  loss:
    class: ScaledMAE
    scale: 1.0e6
    # class: CompositeMetricFix
    # metrics:
    # - class: ScaledMAE
    #   scale: 1.0e6
    # - class: ScaledRMSE
    #   scale: 1.0e12
    # - class: ScaledSignRat
    #   scale: 1.0e12
    # - class: AggregationMetric
    #   metric:
    #     class: ScaledMAE
    #     scale: 1.0e6
    # - class: AggregationMetric
    #   metric:
    #     class: ScaledRMSE
    #     scale: 1.0e12
    # - class: AggregationMetric
    #   metric:
    #     class: ScaledAsignRat
    #     scale: 1.0e12
    # weights:
    # - 1.0
    # - 1.0
    # - 1.0
    # - 1.0
    # - 1.0
  log_interval: 0
  reduce_on_plateau_patience: 2
  reduce_on_plateau_reduction: 2
  reduce_on_plateau_min_lr: 1.0e-10
  weight_decay: 0
  logging_metrics:
  - MAE
  - RMSE
  - MAPE
  - SMAPE
  - class: ScaledMAE
    scale: 1.0e6
  - class: ScaledRMSE
    scale: 1.0e12
  - class: ScaledSignRat
    scale: 1.0e12
  - class: ScaledAsignRat
    scale: 1.0e12
  - class: AggregationMetric
    metric:
      class: ScaledMAE
      scale: 1.0e6
  - class: AggregationMetric
    metric:
      class: ScaledRMSE
      scale: 1.0e12
  - class: AggregationMetric
    metric:
      class: ScaledSignRat
      scale: 1.0e12
  - class: AggregationMetric
    metric:
      class: ScaledAsignRat
      scale: 1.0e12
  - class: ROR
    target_kind: rat
    direction: all
    mask_kind: none
  - class: ROR
    target_kind: rat
    direction: all
    mask_kind: max
  - class: ROR
    target_kind: rat
    direction: pos
    mask_kind: max
  - class: ROR
    target_kind: rat
    direction: neg
    mask_kind: max
  - class: ROR
    target_kind: rat
    direction: pos
    mask_kind: none
  - class: ROR
    target_kind: rat
    direction: neg
    mask_kind: none
  - class: ROR
    target_kind: rat
    direction: pos
    mask_kind: all
  - class: ROR
    target_kind: rat
    direction: neg
    mask_kind: all
  - class: ROR
    target_kind: rat
    direction: pos
    mask_kind: last
  - class: ROR
    target_kind: rat
    direction: neg
    mask_kind: last
trainer_kwargs:
  max_epochs: 256
  accelerator: gpu  # cpu
  devices: [ 0 ]
  gradient_clip_val: 0
  gradient_clip_algorithm: norm  # norm or value
  track_grad_norm: 2
  log_every_n_steps: 3000
  limit_train_batches: ~
  logger:
  - class: MLFlowLogger
    experiment_name: ~  # default to model_name
  callbacks:
  # - class: DeviceStatsMonitor
  #   cpu_stats: true
  - class: LearningRateMonitor
    logging_interval: ~
    log_momentum: true
  - class: ModelCheckpoint
    monitor: val_loss
    filename: '{epoch}-{step}-{val_loss:.3f}'
    save_last: true
    save_top_k: 1
  - class: EarlyStopping
    monitor: val_loss
    min_delta: 0
    patience: 9
    verbose: false
    mode: min